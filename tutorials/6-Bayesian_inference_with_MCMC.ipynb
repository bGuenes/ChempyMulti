{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian inference via posterior sampling\n",
    "First we will need to wrap Chempy such that it internally produces priors and likelihoods, and returns a posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ../source/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from parameter import ModelParameters\n",
    "from cem_function import cem\n",
    "a = ModelParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chempy posterior with prior and with best-fit from paper\n",
    "- First we will initialise Chempy with its prior parameters and evaluate the Posterior for Sun+ observational constraint.\n",
    "- Then we initilise Chempy with the best parameters obtained from the MCMC (Figure 11 of the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.testing_output = True\n",
    "a.summary_pdf = True\n",
    "a.observational_constraints_index = ['gas_reservoir','sn_ratio','sol_norm']\n",
    "posterior, blobs = cem(a.p0,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.p0 = np.array([-2.46, -3.07, -0.8, -0.31, 3.02, 0.47, -0.11])\n",
    "posterior, blobs = cem(a.p0,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC workflow\n",
    "A full MCMC sampling of the 7 dimensional parameter space of the paper is too much for this tutorial (though we attach an MCMC chain and visualise the result later). For now we do a little inference for less parameters, lets say high-mass slope and number of SN Ia. This will have to run for a bit, but you can also just use the example uploaded in the github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wrapper import mcmc\n",
    "a.nwalkers = 4\n",
    "a.ndim = 2\n",
    "a.to_optimize = np.array(['high_mass_slope', 'log10_N_0'])\n",
    "a.p0 = np.array([-2.29 ,-2.75])\n",
    "mcmc(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
